{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd9f332",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c472b359",
   "metadata": {},
   "source": [
    "# Convotional neural network\n",
    "\n",
    "This model is a CNN. It is a type of deep learning model that is primarily used for image classification, object detection. It is specifically designed to process and analyze visual data efficiently.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "955a514b",
   "metadata": {},
   "source": [
    "The model class is defined with methods to initialise the dataset, to build the model and to train the model.\n",
    "\n",
    "The init method initializes the training dataset from th \"data/train\" the testing set from \"data/test\".\n",
    "It displays some informations about the dataset, training dataset and the testing dataset, like image batch shapes, class distribution and the mean of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb223c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from utils.x_ray_data_viz import plot_history\n",
    "from utils.x_ray_dataset_builder import Dataset@\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, image_size=(512, 512)):\n",
    "        train_dir = pathlib.Path(\"data/train\")\n",
    "\n",
    "        test_dir = pathlib.Path(\"data/test\")\n",
    "\n",
    "        train_ds = Dataset(\n",
    "            train_dir,\n",
    "            batch_size=64,\n",
    "            image_size=image_size\n",
    "        )\n",
    "\n",
    "        test_ds = Dataset(\n",
    "            test_dir,\n",
    "            batch_size=64,\n",
    "            image_size=image_size,\n",
    "        )\n",
    "\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "        train_ds.build(AUTOTUNE, True)\n",
    "\n",
    "        test_ds.build(AUTOTUNE)\n",
    "\n",
    "        class_names = train_ds.get_class_names()\n",
    "        print(\"\\nClass names:\")\n",
    "        print(class_names)\n",
    "\n",
    "        train_x_batch_shape = train_ds.get_x_batch_shape()\n",
    "        print(\"\\nTraining dataset's images batch shape is:\")\n",
    "        print(train_x_batch_shape)\n",
    "\n",
    "        train_y_batch_shape = train_ds.get_y_batch_shape()\n",
    "        print(\"\\nTraining dataset's labels batch shape is:\")\n",
    "        print(train_y_batch_shape)\n",
    "\n",
    "        train_ds.display_images_in_batch(\n",
    "            1,\n",
    "            \"Training dataset\",\n",
    "            CHART_DIR.joinpath(\"dataset/train_dataset_image_sample.png\"),\n",
    "            interactive=interactive_reports,\n",
    "        )\n",
    "        train_ds.display_batch_number(\n",
    "            \"Training dataset\",\n",
    "            CHART_DIR.joinpath(\"dataset/train_dataset_batch_number.png\"),\n",
    "            interactive=interactive_reports,\n",
    "        )\n",
    "\n",
    "        test_x_batch_shape = train_ds.get_x_batch_shape()\n",
    "        print(\"\\nTesting dataset's images batch shape is:\")\n",
    "        print(test_x_batch_shape)\n",
    "\n",
    "        test_y_batch_shape = train_ds.get_y_batch_shape()\n",
    "        print(\"\\nTesting dataset's labels batch shape is:\")\n",
    "        print(test_y_batch_shape)\n",
    "\n",
    "        test_ds.display_images_in_batch(\n",
    "            1,\n",
    "            \"Testing dataset\",\n",
    "            CHART_DIR.joinpath(\"dataset/test_dataset_image_sample.png\"),\n",
    "            interactive=interactive_reports,\n",
    "        )\n",
    "        test_ds.display_batch_number(\n",
    "            \"Testing dataset\",\n",
    "            CHART_DIR.joinpath(\"dataset/test_dataset_batch_number.png\"),\n",
    "            interactive=interactive_reports,\n",
    "        )\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.class_names = class_names\n",
    "        self.image_size = image_size\n",
    "        self.train_ds = train_ds.normalized_dataset\n",
    "        self.test_ds = test_ds.normalized_dataset\n",
    "        self.x_train = train_ds.x_dataset\n",
    "        self.x_test = test_ds.x_dataset\n",
    "        self.y_train = train_ds.y_dataset\n",
    "        self.y_test = test_ds.y_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa680109",
   "metadata": {},
   "source": [
    "# Build method\n",
    "The build method defines the architecture of the model.\n",
    "\n",
    "The tf.keras.Sequential() function is called to create an instance of a sequential model. The sequential model allows you to stack layers sequentially.\n",
    "\n",
    "The model.add() function are used to add layers. The first layer has 32 filters of size (3, 3) and uses the ReLU activation function.\n",
    "After each layers, we use BatchNormalisation() to normalize the activation of the layer.\n",
    "\n",
    "Also, the model is beeing compiled with the \"rmsprop\" optimizer, and \"binary_crossentropy\" loss function.\n",
    "\n",
    "To resume, this code set up a CNN model with multiple layers, batch normalization, and connected layers.\n",
    "The model is returned with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self):\n",
    "        channels = 1 if IMG_COLOR == \"grayscale\" else 3\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                32,\n",
    "                (3, 3),\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, channels)\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                64, (3, 3), strides=1, padding=\"same\", activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                64, (3, 3), strides=1, padding=\"same\", activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                128, (3, 3), strides=1, padding=\"same\", activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                256, (3, 3), strides=1, padding=\"same\", activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=\"rmsprop\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(),\n",
    "                tf.keras.metrics.Precision(),\n",
    "                tf.keras.metrics.Recall(),\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13515cd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, epochs, max_epochs, k=5):\n",
    "        kfold = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "        fold_number = 1\n",
    "\n",
    "        for train_index, val_index in kfold.split(self.x_train, self.y_train):\n",
    "            print(\n",
    "                \"\\033[91m\"\n",
    "                \"=================================================================\\n\"\n",
    "                f\"**************STARTING TRAINING K-FOLD N°{fold_number}***********\\n\"\n",
    "                \"=================================================================\"\n",
    "                \"\\033[0m\"\n",
    "            )\n",
    "\n",
    "            train_images, val_images = (\n",
    "                self.x_train[train_index],\n",
    "                self.x_train[val_index],\n",
    "            )\n",
    "\n",
    "            train_labels, val_labels = (\n",
    "                self.y_train[train_index],\n",
    "                self.y_train[val_index],\n",
    "            )\n",
    "\n",
    "            print(\"\\033[96mBuilding model...\\n\")\n",
    "\n",
    "            model = self.build()\n",
    "\n",
    "            history = model.fit(\n",
    "                train_images,\n",
    "                train_labels,\n",
    "                batch_size=self.batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=(val_images, val_labels),\n",
    "            )\n",
    "\n",
    "            self.scores = model.evaluate(\n",
    "                self.x_test, self.y_test, batch_size=self.batch_size, verbose=1\n",
    "            )\n",
    "\n",
    "            self.fold_acc.append(self.scores[1] * 100)\n",
    "\n",
    "            self.fold_loss.append(self.scores[0])\n",
    "\n",
    "            print(\"\\033[0m\")\n",
    "\n",
    "            print(\n",
    "                \"\\n\\033[91m\"\n",
    "                \"=================================================================\\n\"\n",
    "                f\"**************TRAINING FOR K-FOLD N°{fold_number} DONE!**********\\n\"\n",
    "                \"=================================================================\"\n",
    "                \"\\033[0m\"\n",
    "            )\n",
    "\n",
    "            print(f\"\\n\\033[91mSaving model n°{fold_number}...\\033[0m\")\n",
    "\n",
    "            model.save(MODEL_DIR.joinpath(f\"model_3_fold_{fold_number}.keras\"))\n",
    "\n",
    "            print(\"\\n\\033[92mSaving done !\\033[0m\")\n",
    "\n",
    "            plot_history(\n",
    "                history,\n",
    "                CHART_DIR.joinpath(\n",
    "                    f\"training_metrics/training_loss_and_accuracy_fold_{fold_number}.png\"\n",
    "                ),\n",
    "                accuracy_metric=\"binary_accuracy\",\n",
    "                interactive=self.interactive_reports,\n",
    "            )\n",
    "\n",
    "            fold_number += 1\n",
    "\n",
    "        print(\"\\nScore per fold\")\n",
    "\n",
    "        for i in range(0, len(self.fold_acc)):\n",
    "            print(\n",
    "                \"\\n------------------------------------------------------------------------\"\n",
    "            )\n",
    "            print(\n",
    "                f\"> Fold {i+1} - Loss: {self.fold_loss[i]} - Accuracy: {self.fold_acc[i]}%\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            \"\\n\\033[92m\"\n",
    "            \"=================================================================\\n\"\n",
    "            \"********************AVERAGE SCORES FOR ALL FOLDS*****************\\n\"\n",
    "            \"=================================================================\"\n",
    "            \"\\033[0m\\n\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"> Average accuracy: {np.mean(self.fold_acc)} (+- {np.std(self.fold_acc)})\"\n",
    "        )\n",
    "\n",
    "        print(f\"> Average loss: {np.mean(self.fold_loss)}\")\n",
    "\n",
    "        print(\n",
    "            \"\\n\\033[91m\"\n",
    "            \"=================================================================\\n\"\n",
    "            \"****************************TRAINING DONE************************\\n\"\n",
    "            \"=================================================================\"\n",
    "            \"\\033[0m\\n\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
